{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yapay Sinir Ağları\n",
    "\n",
    "Bu yazıyı ve kodları hazırlarken, Michael Nielson'ın açık kaynak Neural Networks and Deep Learning adlı [kitabından](http://neuralnetworksanddeeplearning.com) yararlandım.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy hatırlayalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](NumPy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(2, 1)\n",
      "[[1]\n",
      " [2]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "e = np.array([[1,1],\n",
    "              [2,2],\n",
    "              [3,3,]])\n",
    "f = np.array([[1],\n",
    "              [0]])\n",
    "\n",
    "print(np.shape(e))\n",
    "print(np.shape(f))\n",
    "print(e.dot(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [2 2]\n",
      " [3 3]] \n",
      "\n",
      "[[1 2 3]\n",
      " [1 2 3]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(e,\"\\n\")\n",
    "print(e.T,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1] [1 2 3]\n",
      "[2 2] [1 2 3]\n"
     ]
    }
   ],
   "source": [
    "for a, b in zip(e, e.T):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "dVeri = np.array([1,2,3])\n",
    "def dFonk():\n",
    "    dVeri = 2 * dVeri\n",
    "print(dVeri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 6]\n"
     ]
    }
   ],
   "source": [
    "dVeri = 2 * dVeri\n",
    "print(dVeri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 a\n",
      "3 b\n",
      "5 x\n",
      "7 y\n"
     ]
    }
   ],
   "source": [
    "A = [1,3,5,7]\n",
    "B = [\"a\",\"b\",\"x\",\"y\"]\n",
    "for a,b in zip(A,B):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yardimci Fonksiyonlar\n",
    "\n",
    "Sıgmoid fonksiyonu bir nöronun gelen toplam girdiyi, 0 ile 1 arasında bie çıktı değerine dönüştürür. Bu fonksiyonun türevi, kendisi ile 1den cıkarılmış halinin çarpınıma eşittir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Yardimci Fonksiyonlar\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "def sigmoid_turevi(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ağı oluşturalım\n",
    "Her bir katmanda kaç sinir hücresi olacağını bir listeden alarak, ağı oluşturan bir fonksiyon yazalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ag(katmanlar):\n",
    "    b = [np.random.randn(k, 1) for k in katmanlar[1:]] # bias degerleri (ilk katman haric)\n",
    "    W = [np.random.randn(k2, k1) for k1, k2 in zip(katmanlar[:-1],katmanlar[1:])]\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Örnek bir ağ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agirlik :\n",
      "[[ 0.37313489  1.11050626  1.43445521]\n",
      " [ 0.84689401  0.35942712 -0.70476269]\n",
      " [ 0.26567424  1.13243772  0.35098818]\n",
      " [-0.57623927 -0.43655932  1.23179224]] \n",
      "\n",
      "[[-0.31274422 -0.88347583  0.25305668  0.75190778]\n",
      " [ 2.1240994  -0.6057787  -0.88652124 -1.46218646]] \n",
      "\n",
      "bias :\n",
      "[[-0.07981347]\n",
      " [ 0.27985567]\n",
      " [-0.89391988]\n",
      " [-0.57731036]] \n",
      "\n",
      "[[-0.42970308]\n",
      " [ 1.46261448]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "katmanlar = [3, 4, 2]\n",
    "agirlik, bias = ag(katmanlar)\n",
    "\n",
    "print(\"agirlik :\")\n",
    "for w in agirlik:\n",
    "    print(w, \"\\n\")\n",
    "    \n",
    "print(\"bias :\")\n",
    "for b in bias:\n",
    "    print(b, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### İleri Besleme\n",
    "\n",
    "![network.pdf](network.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![noronislem.JPG](noronislem.JPG)\n",
    "\n",
    "\n",
    "Yukarıdaki yapay sinir ağı, 3 katmandan oluşmaktadır.\n",
    "\n",
    "> Birinci katman, girdi olarak $x_1$, $x_2$, $x_3$ verisini alir. \n",
    "\n",
    "ilk katmana özel olarak $a_i(1) = z_i(1) = x_i$dir. \n",
    "\n",
    "> Daha sonraki katmanlardaki nöronlar, bir önceki katmanın ağırlıklı toplamını girdi olarak kabul eder.\n",
    "\n",
    "\n",
    "\n",
    "Genel olarak,\n",
    "\n",
    "> $z_j(t) = \\sum_i w_{j,i}(t) \\times a_i(t-1) + b_j(t)$\n",
    "\n",
    "mesela  $z_4(2) = w_{4,1}(2) \\times a_1(1) + w_{4,2}(2) \\times a_2(1) + w_{4,3}(2) \\times a_3(1) + b_4(2)$dir.\n",
    "\n",
    "> $w_{j,i}(t)$: $\\hspace{1cm}$ $(t-1)$'inci katmandaki $i$'nci nörondan $(t)$'inci katmandaki $j$nci nörona olan bağlantının ağırlık değeridir.\n",
    "\n",
    "Aynı şekilde\n",
    "\n",
    "> $b_{j}(t)$: $\\hspace{1cm}$ $(t)$'inci katmandaki $j$'nci nörona ait bias değeridir\n",
    "\n",
    "Bir nöronun çıktısı, sigmoid fonksiyonuna net girdi değeri verilerek hesaplanır.\n",
    "\n",
    "> $a_j(t) = \\sigma(z_j(t)) = \\frac{1}{1 + e^{z_j(t)}}$\n",
    "\n",
    "\n",
    "#### İleri Besleme Algoritması\n",
    "\n",
    "Ağımız verilen girdi x ve ağırlık w, bias b değerlerine göre bir çıktı üretir. Vektörize edilerek yapılan işlem\n",
    "\n",
    "> $z(t) = w(t) \\cdot a(t-1) + b(t)$\n",
    "\n",
    "> $a(t) = \\sigma(z(t))$\n",
    "\n",
    "Her bir katmandaki nöronlar, önceki katmanlardaki nöron çıktılarını ağırlıklarıyla çarpıp son olarak bias(çapa ya da referans) değeri ekleyerek net girdi olan $z$ değerini bulurlar. Sonraki işlem ise, sigmoid ile çıktı değerini hesaplamaktır.\n",
    "\n",
    "\n",
    "![vektorize.jpg](vektorize.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ileribesleme(a, agirlik, bias):\n",
    "    \"\"\"Katman katman yeni a degerleri hesaplaniyor\"\"\"\n",
    "    for w, b in zip(agirlik, bias):\n",
    "        z = np.dot(w, a)+b\n",
    "        a = sigmoid(z)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33488081]]\n"
     ]
    }
   ],
   "source": [
    "katmanlar = [2, 3, 1]\n",
    "agirlik, bias = ag(katmanlar)\n",
    "\n",
    "girdi = [[0], \n",
    "         [0]]\n",
    "print(ileribesleme(girdi, agirlik, bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yardımcı Türevler\n",
    "\n",
    "İleri Besleme algortimasına bakarak şu türevleri bulalım, bunlar bize geri besleme algoritmasında yardımcı olacak\n",
    "\n",
    "> \n",
    "$$\n",
    "\\frac{d z_j(t+1)}{d z_i(t)} = \n",
    "\\frac{ d (\\sum_i w_{j,i}(t+1) \\times \\sigma(z_i(t)) + b_j(t+1))}{d z_i(t)}\n",
    "=\n",
    "w_{j,i}(t+1) \\times \\sigma'(z_i(t))\n",
    "$$\n",
    "\n",
    "![back1.jpg](back1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geri Besleme\n",
    "\n",
    "Geri besleme algoritmasındaki kilit nokta,\n",
    "bir nöronun ait girdideki değişim, hatayı nasıl etkiler sorusudur.\n",
    "\n",
    "\n",
    "$$\n",
    "\\Delta_j(t) =\n",
    "\\frac{d Hata}{d z_j(t)}\n",
    "$$\n",
    "\n",
    "Bu soruya vereceğimiz cevap ile, ağırlık ve bias değerlerini hatayı minimize edecek şekilde nasıl güncelleyeceğimizi bulacağız. Ve tabi gene gradyan iniş yöntemini kullanacağız.\n",
    "\n",
    "$$Hata = \\frac{1}{2} \\sum_j (y_j - a_j(T))^2$$\n",
    "\n",
    "$T$ ağdaki çıktı katmanıdır. Bu durumda çıktı katmanındaki j'inci nöronun hataya etkisi\n",
    "\n",
    "$$\n",
    "\\Delta_j(T) =\n",
    "\\frac{d Hata}{d z_j(T)} = \\frac{d Hata}{d a_j(T)} \\frac{d a_j(T)}{d z_j(T)}\n",
    "= (a_j(T)-y_j ) \\frac{d a_j(T)}{d z_j(T)}\n",
    "= (a_j(T)-y_j ) \\sigma'(z_j(T))\n",
    "$$ \n",
    "\n",
    "Çıktı katmanındaki tüm nöronların hataya olan etkisini vektörize edersek\n",
    "\n",
    "> \n",
    "$$\n",
    "\\Delta(T) = \\frac{d Hata}{d z(T)} = (a(T)-y) \\sigma'(z(T))\n",
    "$$\n",
    "\n",
    "Dikkat ederseniz, vektörize ettiğimizde indislerden kurtuluyoruz. Peki bir ara katmandan, önceki ara katmana hata nasıl yayılır?\n",
    "\n",
    "> \n",
    "$$\n",
    "\\Delta_i(t) =\n",
    "\\frac{d Hata}{d z_i(t)} \n",
    "= \n",
    "\\sum_j \\frac{d Hata}{d z_j(t+1)} \\frac{d z_j(t+1)}{d z_i(t)}\n",
    "= \n",
    "\\sum_j \\Delta_j(t+1) \\frac{d z_j(t+1)}{d z_i(t)}\n",
    "$$\n",
    "\n",
    "\n",
    "Unutmayın ki, $(t)$'inci katmandaki nöron $i$'ye ait bir hata\n",
    "$(t+1)$'inci katmandaki tüm $j$ nöronlarını etkiler. Sonuç olarak,\n",
    "\n",
    "> \n",
    "$$\n",
    "\\Delta_i(t) =\n",
    "\\sum_j \\Delta_j(t+1) w_{j,i}(t+1) \\times \\sigma'(z_i(t))\n",
    "$$\n",
    "\n",
    "$(t+1)$'inci katmandan $(t)$'inci katmana hatanın akışını vektörize edersek,\n",
    "\n",
    "$$\n",
    "\\Delta(t) =  w^T(t+1) \\cdot  \\Delta(t+1) \\times \\sigma'(z(t))\n",
    "$$\n",
    "\n",
    "![back2.jpg](back2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nöronlardaki hatanın güncellenmesi\n",
    "\n",
    "Çıktı katmanında\n",
    "$$\n",
    "\\Delta(T) = \\frac{d Hata}{d z(T)} = (a(T)-y) \\sigma'(z(T))\n",
    "$$\n",
    "\n",
    "$(t+1)$'inci ara katmandan $(t)$'inci ara katmana hatanın akışı,\n",
    "\n",
    "$$\n",
    "\\Delta(t) =  w^T(t+1) \\cdot  \\Delta(t+1) \\times \\sigma'(z(t))\n",
    "$$\n",
    "\n",
    "### Ağırlık ve bias değerlerinin güncellenmesi\n",
    "\n",
    "Hatayı minimize eden en iyi parametreleri arıyoruz.\n",
    "\n",
    "Ağırlıktaki değişim\n",
    "$$\n",
    "\\frac{d Hata}{d w_{ji}(t)} = \\frac{d Hata}{d z_{j}(t)} \\frac{d z_{j}(t)}{d w_{ji}(t)} \n",
    "= \\Delta_{j}(t)  a_i(t-1)\n",
    "$$\n",
    "\n",
    "Biasdeki değişim\n",
    "$$\n",
    "\\frac{d Hata}{d b_{j}(t)} = \\frac{d Hata}{d z_{j}(t)} \\frac{d z_{j}(t)}{d b_{j}(t)} \n",
    "= \\Delta_{j}(t) \n",
    "$$\n",
    "\n",
    "Geri Besleme algoritması neden hızlıdır?\n",
    "\n",
    "> Dikkat ederseniz $\\Delta_{j}(t)$ değerini sadece bir kez hesaplayıp, yeniden hesaplamadan bir çok yerde (Ağırlıktaki ve Biasdeki değişimde) tekrar tekrar kullanıyoruz. Bu bize hız kazandırıyor.\n",
    "\n",
    "![back3.jpg](back3.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def geribesleme(x,y, agirlik, bias): #girdi, cikti\n",
    "    delta_b = [np.zeros(b.shape) for b in bias]\n",
    "    delta_w = [np.zeros(w.shape) for w in agirlik]\n",
    "    \n",
    "    a = x\n",
    "    A = [a] # a degerleri\n",
    "    Z = []  # z degerleri\n",
    "    for w, b in zip(agirlik, bias):# z ve a degerlerini depolayalim\n",
    "        z = np.dot(w, a) + b\n",
    "        a = sigmoid(z)\n",
    "        Z.append(z)\n",
    "        A.append(a)\n",
    "    \n",
    "    hata = A[-1] - y # en son katmandaki hata\n",
    "    delta = hata * sigmoid_turevi(Z[-1])\n",
    "    delta_b[-1] = delta\n",
    "    delta_w[-1] = np.dot(delta, A[-2].T)\n",
    "    for k in range(2, len(katmanlar)):\n",
    "        delta = np.dot(agirlik[-k+1].T, delta) * sigmoid_turevi(Z[-k])\n",
    "        delta_b[-k] = delta\n",
    "        delta_w[-k] = np.dot(delta, A[-k-1].T)\n",
    "    return (delta_b, delta_w)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradyan_inis(orneklem, adim, agirlik, bias):\n",
    "    delta_b = [np.zeros(b.shape) for b in bias]\n",
    "    delta_w = [np.zeros(w.shape) for w in agirlik]\n",
    "    \n",
    "    for x, y in orneklem:\n",
    "        # geri besleme tek bir x-y cifti icin w-b parametrelerinde degisimi verir\n",
    "        delta_bxy, delta_wxy = geribesleme(x, y, agirlik, bias)\n",
    "        # orneklemdeki farkli x-y ciftleri icin w-b degisimleri toplanir\n",
    "        delta_b = [nb+dnb for nb, dnb in zip(delta_b, delta_bxy)]\n",
    "        delta_w = [nw+dnw for nw, dnw in zip(delta_w, delta_wxy)]\n",
    "    \n",
    "    # w-b parametreleri turevlerinin tersi yonde guncelleniyor (gradyan_inis)    \n",
    "    agirlik = [w-(adim/len(orneklem))*nw for w, nw in zip(agirlik, delta_w)]\n",
    "    bias = [b-(adim/len(orneklem))*nb for b, nb in zip(bias, delta_b)]\n",
    "    return agirlik, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ogrenme(veri, agirlik, bias, epochs = 30, sayi = 10, adim = 0.5, test_data=None):\n",
    "    \"\"\" epochs: kac kez tum veri kullaniacak\n",
    "        icinde sayi kadar ornek bulunan orneklemler(mini-batch)\n",
    "        gradyan-iniste kullaniliyor. Agirlik ve bias degerleri guncelleniyor.\n",
    "        Ogrenme:\n",
    "            en iyi Agirlik ve bias degerelerini bulmak\n",
    "    \"\"\"\n",
    "    veri = list(veri)\n",
    "    n = len(veri)\n",
    "\n",
    "    if test_data:\n",
    "        test_data = list(test_data)\n",
    "        n_test = len(test_data)\n",
    "\n",
    "    for j in range(epochs):\n",
    "        random.shuffle(veri)\n",
    "        for orneklem in [veri[k:k+sayi] for k in range(0, n, sayi)]:\n",
    "            agirlik, bias = gradyan_inis(orneklem, adim, agirlik, bias)\n",
    "        if test_data:\n",
    "            print(\"Epoch {} : {} / {}\".format(j, tahmin(test_data, agirlik, bias), n_test));\n",
    "        else:\n",
    "            print(\"Epoch {} complete\".format(j))\n",
    "    return agirlik, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tahmin(test_data, agirlik, bias):\n",
    "    \"\"\"Return the number of test inputs for which the neural\n",
    "    network outputs the correct result. Note that the neural\n",
    "    network's output is assumed to be the index of whichever\n",
    "    neuron in the final layer has the highest activation.\"\"\"\n",
    "    test_results = [(np.argmax(ileribesleme(x, agirlik, bias)), y) for (x, y) in test_data]\n",
    "    return sum(int(x == y) for (x, y) in test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calisma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 9]\n",
      " [5 8]\n",
      " [9 7]\n",
      " [3 8]\n",
      " [4 5]]\n"
     ]
    }
   ],
   "source": [
    "# 1 ile 10 arasinda 1000 adet x1 ve x2\n",
    "X = np.random.randint(10, size=(1000,2))\n",
    "print(X[1:6,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# ilk kolon ikinci kolondan buyukse, y=1\n",
    "y = (X[:,0] > X[:,1]) * 1\n",
    "print(y[1:6,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x10a13b548>\n"
     ]
    }
   ],
   "source": [
    "veri = zip(X,y)\n",
    "print(veri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 complete\n",
      "Epoch 1 complete\n",
      "Epoch 2 complete\n",
      "Epoch 3 complete\n",
      "Epoch 4 complete\n",
      "Epoch 5 complete\n",
      "Epoch 6 complete\n",
      "Epoch 7 complete\n",
      "Epoch 8 complete\n",
      "Epoch 9 complete\n",
      "Epoch 10 complete\n",
      "Epoch 11 complete\n",
      "Epoch 12 complete\n",
      "Epoch 13 complete\n",
      "Epoch 14 complete\n",
      "Epoch 15 complete\n",
      "Epoch 16 complete\n",
      "Epoch 17 complete\n",
      "Epoch 18 complete\n",
      "Epoch 19 complete\n",
      "Epoch 20 complete\n",
      "Epoch 21 complete\n",
      "Epoch 22 complete\n",
      "Epoch 23 complete\n",
      "Epoch 24 complete\n",
      "Epoch 25 complete\n",
      "Epoch 26 complete\n",
      "Epoch 27 complete\n",
      "Epoch 28 complete\n",
      "Epoch 29 complete\n"
     ]
    }
   ],
   "source": [
    "katmanlar = [2, 5, 1]\n",
    "agirlik, bias = ag(katmanlar)\n",
    "ogrenme(veri, agirlik, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "veri = []\n",
    "test = []\n",
    "ogrenme(veri, agirlik, bias, test_data= test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mnist_loader\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "training_data = list(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = training_data[1:2]\n",
    "np.shape(training_data[1:2])\n",
    "for x, y in t:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "katmanlar = [784, 30, 10]\n",
    "agirlik, bias = ag(katmanlar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ogrenme(training_data, agirlik, bias, 3, 10, 3.0, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agirlik, bias = gradyan_inis(training_data[1:10],adim = 0.5, agirlik = agirlik, bias = bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
